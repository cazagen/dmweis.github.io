# Third week: Tracking!

Finally! This weeks topic is Tracking! Probably my most favorite topic when it comes to VR/AR. Something most people would probably find strange. BUt I consider myself more of an engineer than a game designer/developer and precise tracking and SLAM algorithms have always been an interest of mine. And out of all tracking systems currently used on the market. The Light house tracking system is probably my most favorite. It is in fact the reason behind why I bought my own Vive. Interestingly enought my vive also spends a lot of time just connected to my computer to be simply used as a reciever when I use my controllers as tracking points.

Let me explain why I find the Lighthouse system so fascinating. And let me start from the basics. Tracking has been an integral part of VR ever since VR started becoming more of a comercial product. Even the old headsets that were used in the 80's and 90's used primitive forms of trackign. But it really become interesting around the time of the first Oculus Rift Kickstarer. Originally the Rift (specifically the DK1) only had an IMU (Inertial measurement unit) that can tell you the rientation and partially acceleration (from which we can extrapolate some simple movement). But it become very obvious very soon that this would not be enought. Mostly thanks to motion sickness. You see. humans are interesting creatures. We evolved learning to combine as mnay of our sense to determin our movement. This includes vision, inner ear, sound and to some extend other senses as well (Interesting fact we later replicated in most tracking systems). This has an interesting consequence. If any of those sense go out of sync we imediatly start feeling sick. Our body assumes we are being poisoned (Similarly to why alcohol makes us sick) and tries to ake us vommit the poison out. This is of course inconvinient since vomiting during gaming is not the most comfortable thing to do. And so we started by creating more precise and faster tracking that could also do spatial location.

There are two aproaches to solve this. Inside-out tracking and Outside-In. The difference is pretty simple. And Outside-In system uses external sensors/devices that are not part of the headset that help during the tracking. Such as cameras taht tracking infrared lights on the headset like Oculuses Constelation system, or an infrared tracking beam such as the Lighthouse system. THe other will obviously be one that doesn't rely on any external devices. Such as the DK1 with it's IMU unity that could only determin orientation, or most mobile VR headsets. Or more complexe systems like the Hololens, Google Tango, or others that rely on SLAM (Simultaneous localization and mapping) algorithm with cameras or depth sensing cameras. Now the Outside-In tracking has some obvious adventages. It doesn't requier any external devices, can most lykely also map the enviroment and it potentionally offers an untethered expirience. Problem with them is taht they are difficult to make. They are expensive, complicated and oftentimes are not fast or precise enought for a completly comfortable expirience.

IF we go historically. The first positionally tracked VR headset was the Vlave VR room prototype.

<img src="/../_images/tracking/Valve_VR_room.png" height="300" />
<img src="/../_images/tracking/valve_vr_hmd.jpg" height="300" />
This headset was using fiducial markers (Similar to QR codes. But contrary to popular believe not the same) placed around the entire room. And the headset was constructed using two mobile phone displays and a mobile camera that was used for tracking of the QR codes. Since the position of all of the markers is knowin. We can easily (Relatively) establish pose of the headset.

But this solution obviously ins't ideal. Mostly because having walls covered in tracking markers is not ideal.